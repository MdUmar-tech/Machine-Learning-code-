#source nybermann
#https://github.com/ChoJH98/Self_Teaching
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import accuracy_score, roc_curve
from matplotlib import pyplot as plt
#import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv('sample.csv')

# Separate features and target
Target = df.iloc[:, -1]
print(df.shape)
Features = df.iloc[:, 1:15]

# Label encoding for the target variable
LE = LabelEncoder()
LE.fit(Target)
Target_bin = LE.transform(Target)

# Feature scaling
features_scale=Features
scaler = StandardScaler().fit(features_scale.values)
features_scale = scaler.transform(features_scale.values)

# hyperparametre tuning
from pprint import pprint

# Create a Random Forest Classifier
clf = RandomForestClassifier()

# Define the hyperparameter grid
param_grid = {
    "n_estimators": [10, 100, 500, 1000],
    "max_depth": [1, 5, 10, 15],
    "min_samples_leaf": [1, 2, 4, 10, 15, 30, 50]
}

# Perform grid search cross-validation
grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10)
grid_search.fit(X_train, y_train)

# Print the best hyperparameters
print("Best hyperparameters:")
pprint(grid_search.best_params_)

# Extract optimal hyperparameters
optimal_estimators = grid_search.best_params_.get("n_estimators")
optimal_depth = grid_search.best_params_.get("max_depth")
optimal_leaf = grid_search.best_params_.get("min_samples_leaf")

# Make predictions using the best model
grid_predictions = grid_search.predict(X_test)

#########################################################
#after hyperparametre tuning 
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features_scale, Target_bin, test_size=0.3, stratify=Target_bin)


# Create a Random Forest Classifier
clf = RandomForestClassifier(n_estimators=500, max_depth=15, min_samples_leaf=1)
clf.fit(X_train, y_train)# Train the model

# Make predictions
y_pred = clf.predict(X_test)# Predictions on testing set
y_pred_train = clf.predict(X_train)# Predictions on training set

# Evaluate model performance
print("Accuracy on training set:", metrics.accuracy_score(clf, y_train))
print("Accuracy on testing set:", metrics.accuracy_score(clf, y_test))

# Calculate ROC AUC scores
print("ROC AUC score on training set:", metrics.roc_auc_score(clf, y_train))
print("ROC AUC score on testing set:", metrics.roc_auc_score(clf, y_test))

# Visualize feature importances
features = Features.shape[1]
plt.figure(figsize=(8, 15))
plt.barh(range(features), clf.feature_importances_, align='center')
plt.yticks(np.arange(features), Features.columns)
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.show()

# Predicting drug targets on prediction dataset
df2 = pd.read_csv('prediction.csv')
Features2 = df2.iloc[:, 1:15]

features_scale2 = Features2
scaler2 = StandardScaler().fit(features_scale2.values)

features_scale2 = scaler2.transform(features_scale2.values)

C = clf.predict(features_scale2)

# Extract the result files
C_df = pd.DataFrame({ 'Predicted_targets': C})
C_df.to_csv('predicted_targets.csv', index=False)

# probability or confidence score
prob = clf.predict_proba(features_scale2)

prob = pd.DataFrame(prob)
prob.to_csv('probability_predictions.csv', index=False)
